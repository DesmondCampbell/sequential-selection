\documentclass{article}


\usepackage[round]{natbib}
\usepackage{amsmath,amssymb,amsthm,bm,enumerate,mathrsfs,mathtools}
\usepackage{latexsym,color,verbatim,multirow}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{geometry}
\usetikzlibrary{shapes,arrows}
\tikzstyle{block} = [rectangle, draw, fill=white!20,
    text width=7em, text centered, rounded corners, minimum height=4em]
\tikzstyle{title} = [text width=7em, text centered, font=\bfseries]
\tikzstyle{line} = [draw, -latex']


\usepackage{mycommands}

\begin{document}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{model}[theorem]{Model}

\theoremstyle{definition}
\newtheorem{example}{Example}

\newcommand{\cM}{\mathcal{M}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\FDR}{\textnormal{FDR}}
\newcommand{\FCR}{\textnormal{FCR}}
\newcommand{\crt}{\phi}
\newcommand{\M}{\mathcal{M}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\Gv}{\;\;\big|\;\;}
%\newcommand{\cP}{\mathcal{P}}
\newcommand{\proj}{\cP}
\newcommand{\pow}{\text{Pow}}
\newcommand{\sF}{\mathscr{F}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\sC}{\mathscr{C}}
\newcommand{\hJ}{\widehat{J}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\tM}{\widetilde{M}}
\newcommand{\tE}{\widetilde{E}}
\newcommand{\tV}{\widetilde{V}}
\newcommand{\tR}{\widetilde{R}}
\newcommand{\tL}{\widetilde{L}}
\newcommand{\hk}{\hat{k}}
\newcommand{\hr}{\hat{r}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\leqAS}{\overset{\textrm{a.s.}}{\leq}}


\newcommand*\mystrut{\vrule width0pt height0pt depth1.5ex\relax}
\newcommand{\underlabel}{\underbracket[1pt][.5pt]{\mystrut \quad\;\; \sub \quad\;\; }}
\newcommand{\JTcomment}[1]{{\color{blue}{(JT: \bf \sc #1) }}}
\newcommand{\WFcomment}[1]{{\color{red}{(WF: \bf \sc #1) }}}

\title{Adaptive Sequential Model Selection}
\author{William Fithian, Jonathan Taylor, Rob Tibshirani, and Ryan Tibshirani}
\maketitle

\begin{abstract}
  Many model selection algorithms produce a ``path'' of fits that can be veiwed as specifying a sequence of models of increasing complexity. Given such a sequence of models and the data set used to produce them, we consider the problem of choosing the least complex model that is not falsified by the data, while accounting for the fact that the model path is determined adaptively using the data. Extending the tools of Fithian, Sun and Taylor (2014), we construct a $p$-value for each step in the sequence. In the case of linear regression, our $p$-values improve on the power of the spacings test of \citet{taylor2014exact}, often dramatically. By combining our $p$-values with stopping rules proposed by \citet{gsell2013sequential}, we achieve adaptive control of the familywise error rate and false discovery rate.
\end{abstract}


\section{Introduction}

... generates a sequence of increasingly complex models. Our goal is to choose the simplest model that is not falsified by the available data.

... and find the index of the smallest adequate model --- that is, the smallest model that cannot be falsified given available evidence.

\begin{example}[Forward-Stepwise Linear Regression with the LASSO]
  \citet{taylor2014exact}
\end{example}

\begin{example}[The LARS Algorithm in Regression]
  \citet{taylor2014exact}
\end{example}

\begin{example}[Ever-Active Path in $\ell_1$-Regularized Methods]
  \citet{taylor2014exact}
\end{example}

\begin{example}[Principal Components Analysis]
  As a second motivating example, consider model selection for   principal components analysis. In that case we are given a data matrix $X \in \R^{n\times d}$, with which we form a sample covariance matrix
\[
S = \frac{1}{n-1} \sum_{i=1}^n(x_i - \bar x)^2
\]
The first $d$ principal component loadings are the first $d$ eigenvectors of $S$, which call $u_1,\ldots, u_d$. These induce a sequence of nested Wishart models:
\[
M_0 \sub M_1 \sub \cdots \sub M_d
\]
in which
\begin{equation}
  M_k:\; (n-1) S \sim W_d\left(\lambda_0 I_d + \sum_{i=1}^k     \lambda_i u_i u_i', \;\;\; n-1\right).
\end{equation}
This problem was studied in \citet{choi2014selecting}.
\end{example}

\subsection{Generic Setting}

More generically, we observe data $Y \in \cY$, with unknown sampling distribution $F$. We then use $Y$ to generate an adaptive sequence of $d$ nested models
\[
M_0(Y) \sub M_1(Y) \sub \cdots \sub M_d(Y).
\]
Define the {\em completion index} $k_0(Y) = \min\{k:\; F \in M_k\}$, the index of the first correct model. 

We will consider two related problems. First, we will consider the problem of obtaining selective single-step $p$-values, where $p_k$ is a $p$-value for testing
\[
H_{0,k}:\; F\in M_{k-1}\quad \text{ vs. } \quad 
H_{1,k}:\; F\in M_k\setminus M_{k-1},
\]
while adjusting for the fact that the models are chosen adaptively. As we will see, {\em selected-model} tests can be dramatically more powerful than {\em saturated-model} tests at early steps in the model path when most of the signal variables have not yet entered the model.

The second half of the paper concerns {\em stopping rules} $\hk$, estimators of $k_0$. We will consider several stopping rules that operate on the full sequence $p_{[d]}$, including two powerful stopping rules proposed in \citet{gsell2013sequential}. These latter require guarantees on the joint law of the $p$-values. We will prove sufficient conditions for when the $p$-values are Gaussian.

Although we will focus most of our attention and examples on the case of selecting a set of predictors in linear regression, essentially all of our results apply in generic exponential family models.

\subsection{Which Null Hypothesis Should We Test?}

There is some ambiguity involved in deciding how to generalize $z$- and $t$-tests to the selective case. For example, \citet{gsell2013sequential} describe three different null hypotheses that we could consider testing at step $k$. As discussed at some length in \citet{fithian2014optimal}, there are several different models that 

In some cases the design matrix of the full model may represent a  scrupulously curated set of features, and the analysts may know in advance that inferences with respect to the full model are of major scientific interest. For example, the scientist may believe, due to theoretical considerations, that a nonzero coefficient of $X_1$ after controlling for $X_2,\ldots,X_p$ would be evidence for a causal effect of $X_1$ on the response.

If the full model has no special scientific status, however, then we see little advantage in insisting that all inferences should adjust for every other predictor in the full design matrix $X$. For example, suppose that $X$ contains gene expression measurements for all genes that happened to be measured by a microarry chip. Then $\beta_{j,\text{Full}}$ is already fairly arbitrary, since we would be controlling for a different set of genes if we had purchased the chip from a different manufacturer.

\WFcomment{Also say: Controlling for more variables could take us farther from a causal effect; furthermore, coefficient in larger model is much harder to interpret.}


\section{Inference for One Step}

To begin, we consider the problem of constructing a valid selective $p$-value for a particular step. At step $k$, we construct $p_k(Y)$ to test
\[
  H_{0,k}:\; F \in M_{k-1}(Y)
  \quad \text{ vs. } \quad
  H_{1,k}:\; F \in M_k(Y) \setminus M_{k-1}(Y).
\]
The main complication arises from the fact that the null and alternative hypotheses are random. To simplify matters, we first consider deriving $p$-values for a fixed candidate pair $m_{k-1} \sub m_{k-1}$.

The random variable  $p_{k,M}(Y)$ is a valid {\em selective $p$-value} for the fixed candidate pair $(m_{k-1},m_k)$ if it is stochastically larger than uniform under the (fixed) null $m_{k-1}$, given that the pair $(m_{k-1},m_k)$ is selected. That is,
\[
\P_F\left(p_{k,M}(Y) \leq \alpha \mid M_{k-1}(Y) = m_{k-1}\right) 
\leq \alpha, \quad \forall F\in m_{k-1}, \alpha \in [0,1].
\]
Given selective $p$-values for each fixed candidate pair, we can construct a combined $p$-value for the random null $(M_{k-1},M_k)$: 
\[
p_k(y) = p_{k, M_{k-1}(y), M_k(y)}(y),
\]
which is a valid $p$-value on the event $\{F \in M_{k-1}(Y)\}$:
\[
\P_F\left(p_k \leq \alpha \mid M_{k-1}, \;M_k, 
  \;F\in M_{k-1}\right) \leq \alpha, \quad \forall \alpha \in [0,1].
\]
Recall that, as usual, $F$ is not random, but $M_{k-1}$ is.

Methods for one-step selective $p$-values are by now well-studied. \WFcomment{big list of references.} See \citet{fithian2014optimal} for a general treatment. 

\subsection{Selective $p$-Values in Regression}

\subsection{Selected- and Saturated-Model inference}

We illustrate the superior power of the selected-model test in early steps with an extended example.

\begin{example}[Bivariate Regression]\label{ex:bivariate}
  Consider forward stepwise selection in a regression model with $n=p=2$, with identity design $X = I_2=\begin{pmatrix} 1 & 0 \\ 0 & 1\end{pmatrix}$ and known $\sigma^2=1$. We perform one step of forward stepwise and then test the null model with no variables against the model with one variable. 

We will choose variable 1 first on the selection event $A=\{|Y_1| > |Y_2|\}$, which is shown in yellow in Figure~\ref{fig:bv_condSets}. In that case,
\[
M_0:\; Y\sim \cN(0,I_2), \quad\text{ and } 
M_1:\; Y \sim \cN\left(\binom{\mu_1}{0}, \; I_2\right).
\]
The selected-model test compares $Y_1$ to its distribution under $M_0$ conditional on $A$, a test of $H_0:\;\mu_1=0$ in model $M_1$.

By contrast, the saturated-model test is a test of $H_0:\; \mu_1=0$ in the model $M_{\text{sat}}:\; Y \sim \cN(\mu, I_2)$. Now, $\mu_2$ enters the problem as a nuisance parameter because the saturated-model test refuses to assume that $\mu_2=0$. To eliminate the nuisance parameter $\mu_2$, the saturated model test must condition on $Y_2$, and compare $Y_1$ to its null distribution given $A$ {\em and} the observed value of $Y_2$.

Figure~\ref{fig:bv_condSets} shows the conditioning sets for each model when $Y=(2.9,2.5)$. Next to it, Figure~\ref{fig:bv_nullDists} shows the null distribution for the test statistic $Y_1$ in each case. The $p$-values for the selected and saturated models are 0.007 and 0.3, respectively. These two plots are reproduced from \citet{fithian2014optimal}, in which the same example was presented in less detail.
\end{example}

\begin{figure}
  \centering
  \begin{subfigure}[t]{.4\textwidth}
    % source code: bivariateSelVSat.R
    \includegraphics[width=\textwidth]{figs/bivariateSelVSat_condSets.pdf}
    \caption{\WFcomment{Copied directly from FST14; reword} 
      For $Y=(2.9,2.5)$, the selected-model conditioning set is
      $A=\{y:\;|y_1|>|y_2|\}$, a union of quadrants,
      plotted in yellow. The saturated-model conditioning set
      is ${\{y:\; y_2=2.5\}\cap A} = {\{y:\;y_2=2.5, |y_1|>2.5\}}$,
      a union of rays, plotted in brown.}
    \label{fig:bv_condSets}
  \end{subfigure}
  \hspace{.1\textwidth}
  \begin{subfigure}[t]{.4\textwidth}
    % source code: bivariateSelVSat.R
    \includegraphics[width=\textwidth]{figs/bivariateSelVSat_nullDists.pdf}
    \caption{\WFcomment{Copied directly from FST14; reword} 
      Conditional distributions of $Y_1$ under
      $H_0:\mu_1 = 0$. Under the hypothesis
      $\mu=0$, the realized  $|Y_1|$ is  quite large given $A$,
      giving  $p$-value 0.015. By contrast, $|Y_1|$ is not too large
      given $A \cap \{y:\; y_2=Y_2\}$, giving
      $p$-value 0.3.}
  \end{subfigure}
  \caption{\WFcomment{Copied directly from FST14; reword} 
    Contrast between the saturated-model and selected-model tests
    in Example~\ref{ex:bivariate}, in which we fit a one-sparse model with
    design matrix $\bX=I_2$. The selected-model test is based
    on  $\L_0(Y_1 \gv A)$, whereas the saturated-model test is based
    on $\L_0(Y_1  \gv  Y_2, A)$.}
  \label{fig:bv_nullDists}
\end{figure}


The case illustrated in Figure~\ref{fig:bv_condSets} exhibits a phenomenon that has been remarked upon elsewhere in the literature of saturated-model tests: when there are near-ties between strong variables that are competing to enter the model, the winning variable may have a very weak $p$-value. \WFcomment{add references}. Figure~\ref{fig:bv_rocCurve} displays the cumulative distribution function for the first $p$-value when $\mu=\binom{4}{4}$, a very strong signal. While the selected model test has near perfect power, it is not uncommon for the saturated model test to produce large $p$-values, even in the range of 0.5-0.9. These large $p$-values arise exactly when there is a near tie between the variables.

\begin{figure}
  \centering
  % source code: bivariateSelVSat.R
  \includegraphics[width=.5\textwidth]{figs/bivariateSelVSat_rocCurve.pdf}
  \caption{\WFcomment{Write caption here.}}
  \label{fig:bv_rocCurve}
\end{figure}

Results in \citet{fithian2014optimal} show that the selected-model test is strictly more powerful when the selected model is correct; i.e., when $\mu_2=0$. Figure~\ref{fig:bv_powCurves_0} shows the power curve for each test when $\mu_2=0$. While the selected-model test is more powerful, the difference between the two is relatively mild. Interestingly, the difference is much more pronounced when $\mu_2=4$, as shown in Figure~\ref{fig:bv_powCurves_4}.

\begin{figure}
  \centering
  \begin{subfigure}[t]{.4\textwidth}
    % source code: bivariateSelVSat.R
    \includegraphics[width=\textwidth]{figs/bivariateSelVSat_powCurves_0.pdf}
    \caption{\WFcomment{Write caption here.}}
    \label{fig:bv_powCurves_0}
  \end{subfigure}
  \hspace{.1\textwidth}
  \begin{subfigure}[t]{.4\textwidth}
    % source code: bivariateSelVSat.R
    \includegraphics[width=\textwidth]{figs/bivariateSelVSat_powCurves_4.pdf}
    \caption{\WFcomment{Write caption here.}}
  \end{subfigure}
  \caption{\WFcomment{Write caption here.}}
   \label{fig:bv_powCurves_4}
\end{figure}



\section{Sequential Inference}

Having discussed methods for constructing single-step $p$-values, we turn now to the problem of constructing a {\em stopping rule}; that is, an estimator $\hk$ of the completion index $k_0(Y)\in \{0,\ldots,d,\infty\}$. $M_k$ is ``rejected'' if and only if $\hk>k$. Thus $\hk$ is the number of models we rejected, while $k_0$ is the number that we should have rejected. The number of type I errors, then, is $(\hk-k_0)_+$, while the number of type II errors is $(k_0-\hk)_+$. Define $V=(\hk-k_0)_+$, the number of excess rejections.

Note that the type I error $V$ is defined in a ``model-centric,'' as opposed to a ``variable-centric,'' fashion: in regression, our model-wise $V$ counts the number of true null {\em models} incorrectly rejected, instead of counting the number of noise variables included in the final model. We can define the (model-wise) familywise error rate (FWER) and false discovery rate (FDR) respectively as $\P_F(V >0)$ and $\E_F[V/(\hk \vee 1)]$. 

We could have instead defined the ``variable-centric'' type I error $\tV$ as the number of noise variables incorrectly included in the final model, with $\tR$ denoting the total number of variables included. Here, by ``noise variable'' we mean one that has a non-zero coefficient in the full model. Using selective inference to control the variable-wise FWER $\P_\mu(\tV>0)$ and FDR $\E[\tV / (\tR \vee 1)]$ is an interesting topic for further study.

\subsection{Stopping Rules}

We will consider stopping rules that depend on the sequence $p_1,\ldots,p_d$ of $p$-values, which have been studied in the literature by \WFcomment{literature review here.} We will focus on three such stopping rules: simple stop, proposed by \WFcomment{whom?}, and the more refined strong stop and forward stop, proposed by \citet{gsell2013sequential}. 

While strong stop and forward stop tend to give more powerful stopping rules, they require independence among the $p$-values. Sections~\ref{sec:modelSPSP}--\ref{sec:pvalSP} discuss conditions on the model sequence $M_{[d]}$ and the $p$-value sequence $p_{[d]}$ under which selective $p$-values are mutually independent. We will see that, typically, selected-model $p$-values are sequentially independent while saturated-model $p$-values are not.

\subsubsection{Basic Stop:}

\WFcomment{Is there a better name for this? Can we find it in the literature?}

The most obvious sequential procedure is to reject at each step until the first time $p_k > \alpha$, which we can formalize as
\[
\hk_B(Y) = \min\left\{k \in \{1,\ldots,m\} :\;
  p_k > \alpha\right\} - 1
\]
We will call this procedure {\em basic stop}. 

If $k_0$ is fixed, then it is clear that $\hk_b$ controls the FWER at level $\alpha$ provided that $p_{k}$ is a valid $p$-value for each $k>k_0$. Then, 
\[
\P(V>0) = \P(p_{k_0+1} \leq \alpha) \leq \alpha.
\]
\WFcomment{Trivial, but no doubt someone else proved this first...}

Selectively valid single-step $p$-values do not necessarily guarantee FWER control when $k_0$ is random. In that case, we need a bit more, but it is sufficient that we have type I error control for $p_k$ conditional on $k_0=k-1$; i.e., not just conditional on $M_{k-1}$ being a correct model, but given that $M_{k-1}$ is the {\em first} correct model.

\subsubsection{Strong Stop:}

\citet{gsell2013sequential} propose another stopping rule that controls the model-wise FWER, which they called {\em strong stop}. Define
\[
  \hk_{S}(Y) = \max\left\{k \in \{1,\ldots,d\} :\;
    \exp\left(\sum_{i=k}^d \frac{\log p_i}{i}\right) 
    \leq \frac{\alpha k}{d}\right\}
\]
Even if $p_k$ is a little larger than $\alpha$, say $\alpha=0.05$ and $p_k=0.06$, strong stop can still reject $M_{k-1}$ if the next three or four $p$-values are also relatively small.

\citet{gsell2013sequential} show that if the completion index $k_0$ is fixed, then $\hk_S$ controls the FWER at level $\alpha$, as long as the null $p$-values are independent given the non-null ones. Specifically, they require that
\begin{equation}\label{eq:indepCond_fixed_k0}
\P(p_{k_0+1} \leq \alpha_{k_0+1}, \ldots, p_d \leq \alpha_d
\mid p_1, \ldots, p_{k_0}) \leq \prod_{i=k_0+1}^d \alpha_i
\end{equation}

For random $k_0$, it is easy to see that the $p$-values simply need to satisfy~\eqref{eq:indepCond_fixed_k0} conditional on the value of $k_0$:
\begin{equation}\label{eq:indepCond_random_k0}
  \P(p_{k+1} \leq \alpha_{k+1}, \ldots, p_d \leq \alpha_d
  \mid p_1, \ldots, p_{k_0}, \; k_0 = k) \leq \prod_{i=k+1}^d \alpha_i
\end{equation}
If~\eqref{eq:indepCond_random_k0} holds, then strong stop controls theprobability of $V>0$ conditionally on $k_0$, and thus also marginally.

\subsubsection{Forward Stop:}

\citet{gsell2013sequential} propose another stopping rule, {\em forward stop}, that controls the model-wise FDR:
\[
  \hk_{F}(Y) = \max\left\{k \in \{1,\ldots,d\} :\;
    -\frac{1}{k}\sum_{i=1}^k \log(1-p_i) \leq \alpha\right\}
\]
If $p_k$ is uniform then  $-\log(1-p_k)$ is an exponential random variable. If all of the null $p$-values are uniform and the others are zero, then only the null ones contribute to the sum, and
\[
\widehat{\text{FDR}}_k = -\frac{1}{k}\sum_{i=1}^k \log(1-p_i)
\]
is a Gamma random variable with mean $V/k$ and variance $V/k^2$. We stop the last time the estimate of FDR is less than $\alpha$. Forward stop requires the same condition independence condition~\eqref{eq:indepCond_random_k0} as strong stop does.


\subsection{$p$-Values and Independence}

Recall that $p_k$ is a valid selective $p$-value for $M_{k-1}\sub M_\infty$ if, for all $F\in M_\infty$,
\[
\P_F(p_k \leq \alpha \mid M_{k-1},\; F\in M_{k-1}) \leqAS \alpha.
\]
Valid single-step selective $p$-values do not generally result in $p$-values that are independent from one step to the next. 

For example, saturated-model $p$-values are generically non-independent. Continuing with Example~\ref{ex:bivariate}, Table~\ref{tab:bv_twoWayTable} shows a two-way contingency table for the saturated-model $p$-values $(p_1(Y), p_2(Y))$, binned into cells of height and width 0.2, simulated under the global null $\mu=0$. Because $k_0=0$, both $p$-values are uniform by construction, but the $p$-values are strongly dependent, with correlation $-48\%$. By contrast, we will see that the selected-model $p$-values $(p_1,p_2)$ are independent under the global null, a consequence of Proposition~\ref{prop:selectiveModel}.

% latex table generated in R 3.0.2 by xtable 1.7-1 package
% Mon May  4 21:11:15 2015
\begin{table}[ht]
  \centering
  \begin{tabular}{l|ccccc|c}
    \multicolumn{7}{c}{Saturated-Model $p$-Values 
      (\% of $10^6$ Simulations)}\\[7pt]
    \hline
    \multicolumn{7}{c}{}\\[-1.5ex]
    \multicolumn{7}{c}{$p_2(Y)$}\\[5pt]
    ${\large p_1(Y)}$ & (0,0.2] & (0.2,0.4] & (0.4,0.6] & (0.6,0.8] & (0.8,1] & \textbf{Total} \\ 
    \hline
    (0,0.2] & 1.0 & 2.7 & 4.2 & 5.6 & 6.7 & 20.1 \\ 
    (0.2,0.4] & 1.4 & 3.4 & 4.5 & 5.2 & 5.5 & 20.0 \\ 
    (0.4,0.6] & 2.3 & 4.3 & 4.7 & 4.5 & 4.2 & 20.0 \\ 
    (0.6,0.8] & 4.2 & 5.4 & 4.3 & 3.4 & 2.7 & 20.0 \\ 
    (0.8,1] & 11.1 & 4.3 & 2.3 & 1.4 & 1.0 & 20.0 \\ 
    \hline
    \textbf{Total} & 19.9 & 20.0 & 20.0 & 20.1 & 20.0 & 100.0 \\ 
    \hline
  \end{tabular}
  \caption{Two-way contingency table of saturated-model $p$-values $(p_1(Y), p_2(Y))$ for Example~\ref{ex:bivariate}, after binning into cells of height and width 0.2. We report the percentage of $p$-value pairs falling into each cell out of one million simulations from the global null hypothesis, $\mu=0$. Both $p$-values are marginally uniform but strongly dependent, with a correlation of $-48\%$.}
\label{tab:bv_twoWayTable}
\end{table}

First, note that $p_2$ is a selective $p$-value for comparing the null with only variable 1,
\[
M_1:\; Y \sim \cN\left(\binom{\mu_1}{0}, I_2\right),
\]
against the alternative with variables 1 and 2:
\[
M_2:\; Y \sim \cN\left(\mu, I_2\right), \text{ with } 
\mu_2 \neq 0.
\]
To eliminate the nuisance parameter $\mu_1$, the test conditions on $Y_1$. Thus, $p_2$ is uniform given $Y_1$ on $A$. Second, note that on $A$, $p_1$ is a function only of $Y_1$. Thus, $(p_1,p_2)$ are independent uniform variables given that variable 1 is chosen first. By a similar argument, they would also be independent uniforms if $Y_2$ were chosen first; thus, $(p_1, p_2)$ are marginally uniform under the global null.

We now introduce a simple sufficient condition to verify that a given procedure yields independent $p$-values. We say that a filtration $\sF_{[d]}$ with $M_{[k]} \in \sF_k$ {\em separates} the $p$-values $p_{[d]}$ if 
\begin{enumerate}
\item $p_k(Y)$ is conservative given $\sF_{k-1}$ 
  when $F\in M_{k-1}$, and
\item $p_k(Y)$ is measurable with respect to $\sF_k$.
\end{enumerate}
If we think of $\sF_k$ representing information available at step $k$, then the first condition means that $p_k$ excludes whatever evidence may have accrued against the null by step $k-1$, and the second means that information revealed after step $k$ plays no role in determining $p_k$. In that sense, $\sF_k$ forms a ``wall of separation'' between the $p$-values up to $k$ and the ones after $k$. As a result, separated null $p$-values are independent.

\begin{proposition}[Independence of 
  Separated $p$-Values]\label{prop:jointConserv}

  Let $p_{[d]}$ be selective $p$-values for $M_{[d]}$, 
  separated by $\sF_{[d]}$.

  If the $p$-values are exact then $p_{k+1}, \ldots, p_d$ are
  uniform given $\sF_{k_0}$ on the event $\{k_0=k\}$.
  
  If they $p$-values are conservative, then for
  $\alpha_{k+1},\ldots,\alpha_d \in [0,1]$,
  \begin{equation}\label{eq:jointConserv}
  \P_F\left(p_{k+1}\leq \alpha_{k+1}, \ldots, p_d \leq \alpha_d\;
    \mid\; k_0 \leq k, \; \sF_k\right) \leqAS \prod_{i=k+1}^d
  \alpha_i.
  \end{equation}
\end{proposition}
Equation~\ref{eq:jointConserv} is slightly weaker than independence, but it guarantees that both Strong Stop and Forward Stop control their target error rates.

\begin{proof}
  We first prove~\eqref{eq:jointConserv}
  by induction. Define $B_i = \{p_i \leq \alpha_i\}$. 
  The base case is
  \[
  \P_F\left(B_d \mid \sF_{d-1}\right)1_{\{k_0 \leq d-1\}} \leqAS \alpha_d,
  \]
  which is true by construction of $p_d$. 
  For the inductive case, note that the
  conditional probability on the left-hand side
  of~\eqref{eq:jointConserv} is
  \begin{align*}
    \P_F\left(B_{k+1}, \ldots, B_d
      \mid \sF_k\right)1_{\{k_0 \leq k\}} 
    &\eqAS \E_F\bigg[ 1_{B_{k+1}} 
    \P_F\left(B_{k+2}, \ldots, B_d
      \mid \sF_{k+1}\right)1_{\{k_0 \leq k+1\}}
    \mid \sF_k\bigg]1_{\{k_0 \leq k\}}\\
    &\leqAS \P_F\left[ B_{k+1}
      \mid \sF_k\right]1_{\{k_0 \leq k+1\}}\prod_{i=k+2}^d \alpha_i
    \quad\;\;\leqAS\;\; \prod_{i=k+1}^d \alpha_i
  \end{align*}

  If the $p_k$ are exact then the above 
  inequalities become equalities, implying uniformity.
\end{proof}

\subsection{Sufficient Filtration}

Assume that each candidate model has a minimal sufficient statistic $T(y; M)$, and write
\[
T_k(Y) = T(Y; M_k(Y)).
\]
For example, in linear regression with known $\sigma^2$, the complete sufficient statistic for model $M(E)$ is $X_E'Y$, and the sufficient statistic at step $k$ is $T_k = X_{E_k}'Y$. 

We will concern ourselves mainly with the {\em sufficient filtration} for path $M_{[k]}$, defined as
\[
\sF_k = \sF(M_{[k]}, T_k),
\]
The sufficient filtration separates $p_{[d]}$ if $p_k$ is conservative given $\sF_{k-1}$ and $\sF_k$-measurable.\footnote{For readers unfamiliar with $\sigma$-algebra notation, this statement can be read as ``$p_k$ is conservative given $(M_{[k-1]}, T_{k-1})$ and is a function of $(M_{[k]}, T_k)$''}

To be a valid selective $p$-value for a single step, $p_k$ only had to condition on $M_{k-1}$. Thus, it is a little more stringent to additionally require $p_k$ to condition on the entire subpath $M_{[k-1]}$ as well as $T_{k-1}$.

In most cases of interest, however, the two requirements are equivalent. First, we typically construct $p_k$ by conditioning on $T_{k-1}$. In fact, $T_{k-1}$ is complete sufficient, then any exact test must condition on $T_{k-1}$ \WFcomment{should we bother proving this?}. Second, most path algorithms of interest (including forward stepwise regression, the ever-active LASSO path, and their generalizations) satisfy a {\em subpath sufficiency principle} (henceforth, SSP): that once we know $M_k$ and its sufficient statistics, we can reconstruct the model path up to step $k$. Thus, most single-step $p$-values are already conservative conditional on $\sF_{k-1}$.

The requirement that $p_k$ be $\sF_k$-measurable has more bite. For example, it excludes saturated-model tests in linear regression. Computing the cutoff for the saturated-model test requires us to know $\proj_{\eta}^\perp Y$, which is not $\sF_k$-measurable.

By contrast, selected-model tests of $M_{k-1}$ against $M_k$ are always $\sF_k$-measurable, because they are based on the law
\begin{equation}\label{eq:selModel}
\L\left(X_{j_k}'Y \mid X_{E_k-1}'Y, E_{k-1}, j_k\right),
\end{equation}
and all of the random variables appearing in~\eqref{eq:selModel} are $\sF_k$-measurable.




\begin{comment}

\begin{theorem}
  Assume that $T(Y; M)$ is a complete sufficient statistic, 
  that $p_k$ are exact selective $p$-values, and that 
  $M_{[d]}$ satisfies EPIC. 

  Then, the sufficient filtration separates $p_{[d]}$ if and only if 
  $p_k \in \sF_k$.
\end{theorem}


It will be useful to introduce the following notation:

\begin{model}[Generalized Sparse Model]\label{mod:genSparse}
  Let $M$ be a model parameterized by $\theta\in \Theta \sub \R^p$:
  \[
  M = \{F_\theta:\; \theta \in \Theta\}.
  \]
  For subsets $E\sub [p]$ define the submodel with active coefficients $E$ as follows:
  \[
  \Theta(E) = \{\theta:\; \theta_j = 0, \;\;\forall j \notin E\}, 
  \quad M(E) = \{F_\theta:\; \theta\in \Theta_E\}.
  \]
  Let $L(\theta; Y)$ denote the likelihood for model $M$.
\end{model}
Note that, although we will make no assumptions about the form of $M$, the results of this section are only useful in cases where we can actually construct single-step $p$-values. At present, that caveat largely restricts us to using exponential family models.

In Model~\ref{mod:genSparse}, the {\em forward stepwise} algorithm proceeds as follows: we first set $E_0(Y)$ arbitrarily, then at step $k=1,\ldots,d$, we define
\begin{align}\label{eq:forwardDef_start}
j_k &= \argmax_j \;\;\sup \left\{L(\theta; Y):\; \theta\in\Theta(E_{k-1} \cup \{j\})\right\} \\
E_k &= E_{k-1} \cup \{j_k\}\\\label{eq:forwardDef_end}
M_k &= M(E_k)
\end{align}

To make this definition more concrete, we can specialize it to several familiar examples:

\begin{example}[Forward Stepwise Regression]
In the case of linear regression with known $\sigma^2$, $p$ is the number of variables and $M$ is $\cN(X\beta, \;\sigma^2I)$. For active set $E \sub [p]$, $M(E)$ is the model $\cN(X_E\beta_E, \;\sigma^2I)$, and $E_0 = \emptyset$. Because the maximized log-likelihood for a linear regression is monotone in the residual sum of squares, the forward stepwise algorithm adds whichever variable reduces the residual sum of squares the most.

For linear regression with unknown $\sigma^2$, there are $p+1$ parameters $(\beta, \sigma^2)$ and $E_0 = \{p+1\}$ because $\sigma^2$ is a parameter for every model.
\end{example}

\begin{example}[Principle Components Analysis]
\WFcomment{Do this one.}  
\end{example}

All forward stepwise procedures satisfy the SPSP.

\begin{proposition}[Forward Stepwise Satisfies SPSP]\label{prop:forwardSPSP}
  The forward stepwise algorithm in Model~\ref{mod:genSparse} as defined in (\ref{eq:forwardDef_start}--\ref{eq:forwardDef_end}) satisfies the SPSP.
\end{proposition}
\begin{proof}
  Let $A$ denote the event $\{M_k = M(E)\}$ for some fixed active set $E$. Letting $T(Y)$ be a sufficient statistic for $m_k$, the likelihood $L$ restricted to $\Theta(E) \times A$ is proportional to a function depending only on $T$. If $L_T$ is the likelihood of $T(Y)$, then
\[
L(\theta; y) = L_T(\theta; T(y)) \;L_{Y\mid T}(y), \;\; \text{ for } (\theta, y) \in  \Theta(E) \times A.
\]
Note that $L_{Y \mid T}(y)$ does not depend on $\theta$ since $T$ is sufficient for $M(E)$.

For $y\in A$ and $i \leq k$, we have $E_i(y) \sub E$. This means that the maximizer in \eqref{eq:forwardDef_start} is attained for some $j\in E$. So, for $i \leq k$, on $A$,
\begin{align}
  j_i &= \argmax_{j\in E} \;\;\sup \left\{L(\theta; Y):\;
    \theta\in\Theta(E_{i-1} \cup \{j\})\right\} \\
  &= \argmax_{j\in E} \;\;\sup \left\{L_T(\theta; T(Y)):\;
    \theta\in\Theta(E_{i-1} \cup \{j\})\right\}. \label{eq:onlyT}
\end{align}
Replacing $L$ with $L_T$ in~\eqref{eq:onlyT} is justified because $\Theta(E_{i - 1} \cup \{j\}) \sub \Theta(E)$ when $E_{i-1}\cup E$ and $j\in E$.

Equation~\eqref{eq:onlyT} shows that $j_1,\ldots, j_{k-1}$ all depend on $Y$ only through $T(Y)$. As a result, it also follows that the sequence $M_{[k-1]}(Y)$ depends only of $T(Y)$.
\end{proof}

Another class of model selection procedures satisfying the SPSP is the sequence ``ever-active'' sets in regularized likelihood methods. For $r=0,1,\ldots$, let $P_r(\theta)$ denote a regularizing penalty, and define
\begin{align}\label{eq:regPathDef_start}
  \hat\theta^{r}(Y) &= 
  \argmin_{\theta\in\Theta} -\log L(\theta; Y) + P_r(\theta) \\
  \tE_r(Y) &= \left\{j:\; \hat\theta_j^s \neq 0 
    \text{ for any } s \leq r \right\}
\end{align}

While the sets $\tE_r$ are nested by definition, we could have $\tE_r = \tE_{r+1}$ for most values of $r$. We will take the sequence of {\em distinct} ever-active sets. Let $R_0=0$, and for $k>0$ let $R_k$ denote the (random) index where the active set actually changes:
\begin{align}
  R_k &= \min\{s:\; \tE_s \neq \tE_{R_{k-1}}\}\\
  E_k &= \tE_{R_k}\\
  \label{eq:regPathDef_end}
  M_k &= M(E_k)
\end{align}
\WFcomment{Slightly sloppy definitions: note that $d$, the number of models, is random. $d$ could be 0 or could be infinite, depending on the data. Also, it isn't really necessary that the $r$ values be integers...}

\begin{proposition}[Regularized Likelihood Paths Satisfy SPSP]\label{prop:regPathSPSP}
Ever-active model paths derived from regularized likelihood methods as in (\ref{eq:regPathDef_start}--\ref{eq:regPathDef_end}) satisfy the sub-path sufficiency principle.
\end{proposition}

\begin{proof}
  Again, let $A$ denote the event $\{M_k = M(E)\}$ for some fixed $E$, and define $T$ and $L_T$ as in the proof of Proposition~\ref{prop:forwardSPSP}. We can partition $A$ into subsets $A_r = A \cap \{R(k)=r\}$.

On the event $A_r$, every $\hat\theta^s$ for $s\leq r$ is supported on $E$. That is, for $s \leq r$, we can write 
\begin{equation}\label{eq:onlyT_Ar}
  \hat\theta^{s} = 
  \argmin_{\theta\in\Theta(E)} -\log L_T(\theta; T(Y)) + P_s(\theta) \quad \text{ on } A_r
\end{equation}
Equation~\label{eq:onlyT_Ar} guarantees that $M_{[k-1]}$ is a function of $T(Y)$ on $A_r$. That is, we can write
\[
M_{[k-1]}(Y) = M_{[k-1]}^r(T(Y)) \quad \text{ on } A_r
\]
It remains only to show that, on $A$, $R_k(Y)$ depends only on $T(Y)$; then we have
\[
M_{[k-1]}(Y) = M_{[k-1]}^{R(T)}(T) \quad \text{ on } A
\]
But $R_k$ is a function of $T$ on $A$ for the same reason: that $\hat\theta^s$ depends only on $T$ until other coefficients enter the model.
\WFcomment{Would the proof be cleaner with $A_r$ defined as $A\cap \{R_k \leq r\}$?}
\end{proof}


\subsection{Independent $p$-Values Via Selection Variables}\label{sec:selectionVariables}

As discussed in \citet{fithian2014optimal}, there are occasions when it is desirable for some reason to condition on more than just the selection event. On these occasions we can introduce a {\em selection variable} --- any random variable that is finer than the indicator of the selection event --- and condition on its value. Conditioning on a finer selection variable preserves validity conditional on the selection event, but tends to reduce the power of a test. 

For example, in linear regression after selecting variables via the lasso, \citet{lee2013exact} propose conditioning not only on the set of active variables but also on the signs of the active coefficients. The selection event corresponding to a given active set $E\sub [p]$ typically contains up to $2^{|E|}$ convex polytopes, each of which corresponds to a particular sign pattern $\hat z_E$. Thus, conditioning on the selection variable $\hat z_E$ can simplify computation considerably.

We say that $p_{k,M}$ is a selective $p$-value with respect to selection variable $S(Y)$ if it is uniform under $F\in m_k$ given $S$. 

To achieve joint error control properties among different tests, we may need to condition on a finer variable.
\end{comment}

\section{Simulation: Sparse Linear Regression}\label{sec:sparseReg}

Next we compare several model selection procedures in simulation. We simlate from a linear regression model with $n=100$ observations and $p=40$ variables. The design matrix $X\in\R^{n\times p}$ is a random Gaussian design with pairwise correlations of 0.3 between predictor variables.

The columns of $X$ are normalized to have length 1, and we simulate from $Y \sim \cN(X\beta,I_n)$, using a seven-sparse model with signal-to-noise ratio 5:
\[
\beta_j = \left\{\begin{matrix}5 & j = 1,\ldots,7\\ 0 &
    j>7\end{matrix}\right.
\]
We use known $\sigma^2=1$, so that we can compare the saturated-model test with the selected-model test. For our selection algorithm, we use the entire forward-stepwise path, for all 40 steps. 

\subsection{Single-Step $p$-Values}

For each step we compute one-step selected-model and saturated-model $p$-values, as well as nominal (unadjusted) $p$-values, conditioning on the signs of the active variables to make the problem more computationally tractable. Figure~\ref{fig:simulation_null_false} shows the power of all three tests for each of the first ten steps, conditional on the event that the null hypothesis is false. It is clear from Figure~\ref{fig:simulation_null_false} that the selected-model $p$-values are far more powerful than the saturated-model $p$-values. The nominal $p$-values are also quite powerful, but they do not have the correct level.

\begin{figure}
  \centering
  % source code: ??? for simulation, sparseSim.R for plotting
  \includegraphics[width=.8\textwidth]{figs/simulation_snr_5_alpha_05_null_false.pdf}
  \caption{CDFs of saturated-model (black), selected-model (red), and nominal (blue) $p$-values in the simulation of Section~\ref{sec:sparseReg}, conditional on testing a false null hypothesis at step $k$. The selected-model test is much more powerful than the saturated-model test. The nominal test appears powerful, but is not a correct $p$-value.}
  \label{fig:simulation_null_false}
\end{figure}

\begin{figure}
  \centering
  % source code: ??? for simulation, sparseSim.R for plotting
  \includegraphics[width=.8\textwidth]{figs/simulation_snr_5_alpha_05_null_true.pdf}
  \caption{CDFs of saturated-model (black), selected-model (red), and nominal (blue) $p$-values in the simulation of Section~\ref{sec:sparseReg}, conditional on testing a true null hypothesis at step $k$. The selected-model test is much more powerful than the saturated-model test. The nominal test is badly anti-conservative.}
  \label{fig:simulation_null_true}
\end{figure}

\begin{figure}
  \centering
  % source code: ??? for simulation, sparseSim.R for plotting
  \includegraphics[width=.8\textwidth]{figs/simulation_snr_5_alpha_05_noise_var.pdf}
  \caption{CDFs of saturated-model (black), selected-model (red), and nominal (blue) $p$-values in the simulation of Section~\ref{sec:sparseReg}, conditional on the event that the variable added at step $k$ is a noise variable in the full model. Here, none of the methods produce uniform $p$-values. The null hypothesis is false in most cases and so --- in our model-centric point of view --- rejection is the desired outcome.}
  \label{fig:simulation_noise_var}
\end{figure}

Figure~\ref{fig:simulation_null_true} shows the distribution of $p_k$ for $k = 8, \ldots, 17$, given that the null hypothesis tested at step $k$ is correct (i.e., that $k_0< k$). Because the correct model is seven-sparse, $k=8$ is the first index for which the null can possibly be true. Both selective $p$-values are uniform by construction, but the nominal $p$-values are highly anti-conservative, as expected.

Finally, as a warning against misinterpretation of our method, we include Figure~\ref{fig:simulation_noise_var} showing the first ten $p$-values for each method, conditional on event that the variable added at step $k$ is a noise variable in the full model. Now, none of the $p$-values are uniform. 

This is {\em not} a mistake in our implementation of the method, but rather a consequence of our ``model-centric'' point of view. If we try to add a noise variable to the model before we have included all the signal variables, then we are testing a false null hypothesis. The test rejects because there is much more signal to find, and as such, it is entirely appropriate for us to reject the null and continue growing the model.

\subsection{Model-Selection Performance}

If we combine the saturated-model or selected-model $p$-values with one of our three stopping rules, we can evaluate the model-selection performance of each method in terms of:
\begin{itemize}
\item its probability of selecting a correct model or $p_{\text{screen}}$,
\item its model-wise FWER,
\item its model-wise FDR, and
\item its variable-wise FDR, where we use $\tV= \#\{\text{ noise variables included in } M_{\hk}\}$ instead of $V=(\hk-k_0)_+$.
\end{itemize} 
The last measure of performance is not explicitly controlled by any of the selective-inference methods, but we might nevertheless hope to perform reasonably. \WFcomment{Comment on results once they are correct. These numbers are wrong right now.}

\WFcomment{Should we compute the FWER and FDR only conditional on screening? Strong / Forward / Simple should all be correct given screening since they condition on $p_{[k_0-1]}$.}

% latex table generated in R 3.0.2 by xtable 1.7-1 package
% Fri May  1 09:29:28 2015
\begin{table}[ht]
  \centering
  \begin{tabular}{llcccc}
    \hline
    Method & Stopping Rule & $p_{\text{screen}}$ & $\text{FWER}_{\text{mod}}$ 
    & $\text{FDR}_{\text{mod}}$ 
    & $\text{FDR}_{\text{var}}$ \\ 
    \hline
    Selected & Basic & .290 & .000 & .002 & .039 \\ 
    Selected & Forward & .559 & .027 & .020 & .066 \\ 
    Selected & Strong & .041 & .014 & .008 & .042 \\ 
    \hline
    Saturated & Basic & .000 & .000 & .000 & .028 \\ 
    Saturated & Forward & .014 & .000 & .000 & .030 \\ 
    Saturated & Strong & .000 & .000 & .000 & .032 \\ 
    \hline
    Knockoffs & & .000 & --- & --- & .231 \\ 
    \hline
  \end{tabular}
  \caption{\WFcomment{Comment on results once they are correct. These numbers are wrong right now.}}
\end{table}



\section{Simulation: Principal Components Analysis}\label{sec:pca}

\WFcomment{Can we do this one?}


\section{Discussion}


\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}


\begin{comment}
Sections~\ref{sec:pvalSP}--\ref{sec:modelSPSP} discuss sufficient conditions on the $p$-values and the selection algorithm under which single-step $p$-values are automatically independent. Section~\ref{sec:selectionVariables} discusses how we can create independent $p$-values by conditioning on finer selection variables at each step.

Essentially, we will want to partition the information in $Y$ according to the filtration:
\begin{align}\nonumber
  \sF(M_0,T_0) &\underlabel_{\text{selection } 1} 
  \sF(M_{[1]},T_0) \underlabel_{\text{inference } 1}
  \sF(M_{[1]},T_1) \quad \sub \;\;\cdots\\[8pt]
  \label{eq:infoPartition}
  \cdots\;\; \sub \quad&
  \sF(M_{[d-1]},T_{d-1}) \underlabel_{\text{selection } d}
  \sF(M_{[d]},T_{d-1}) 
  \underlabel_{\text{inference } d}
  \sF(M_{[d]}, T_d)
\end{align}

\end{comment}

\begin{comment}
\WFcomment{There is a filtration interpretation when you have the appropriate sufficiency properties.} Let $\sF_{k,i}$ denote the $\sigma$-algebra generated by $M_{[k]}$ and $p_{[i]}$.
\begin{align*}
  \sF_{k,i} &= \sF(M_{[k]},p_{[i]})\\
  \sF_0 &\underlabel_{\text{selection } 1} \sF_{1,0} \underlabel_{\text{inference } 1}
  \sF_{1,1} \;\;\sub \cdots \sub\;\;
  \sF_{d-1,d-1} \underlabel_{\text{selection } d} \sF_{d,d-1}
  \underlabel_{\text{inference } d} \sF_{d,d}
\end{align*}
\end{comment}
